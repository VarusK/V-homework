# IT伦理与道德研究——AI技术

首先，我们从道德和伦理层面提出一个总论题：我们应如何审视人工智能？并，引用一个来自业界专业人士的观点作为本文的总起：
>"While AI is by no means human, by no means can we treat it like just a program," said Michael Biltz, managing director of Accenture Technology Vision at consulting firm Accenture. "In fact, creating AIs should be viewed more like raising a child than programming an application. That's because AI has grown to the point where it can have just as much influence as the people using it." 
（译：Accenture Technology Vision 的总经理 Michael Biltz 说：“虽然人工智能绝不是人类，但我们绝不能把它当成一个程序。” “事实上，创建AI应该更像是抚养孩子而不是编写应用程序。这是因为人工智能已经发展到可以产生与使用它的人一样多的影响力。”）

源：https://www.zdnet.com/article/the-ethical-challenges-of-artificial-intelligence/

经过搜集,我发现有一篇文章列出了当今世界对于 AI 的最热 TOP9 话题：
>Top 9 ethical issues in artificial intelligence
>1. Unemployment. What happens after the end of jobs?
>2. Inequality. How do we distribute the wealth created by machines?
>3. Humanity. How do machines affect our behaviour and interaction?
>4. Artificial stupidity. How can we guard against mistakes?
>5. Racist robots. How do we eliminate AI bias?
>6. Security. How do we keep AI safe from adversaries?
>7. Evil genies. How do we protect against unintended consequences?
>8. Singularity. How do we stay in control of a complex intelligent system?
>9. Robot rights. How do we define the humane treatment of AI?

源：https://www.weforum.org/agenda/2016/10/top-10-ethical-issues-in-artificial-intelligence/  

我们以这 9 个话题中的第 1、2、3、6、9 为中心论点展开讨论。

![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1543392195678&di=570f515f73fb6fa8df8319af46993d57&imgtype=0&src=http%3A%2F%2Fn.sinaimg.cn%2Ftranslate%2F110%2Fw580h330%2F20180720%2Ftuj1-hfqtahh5360043.jpg)

经过整理，我们有以下几个来自业界人士的观点：

1. 观点一：
> The possibility of creating thinking machines raises a host of ethical issues. These questions
relate both to ensuring that such machines do not harm humans and other morally
relevant beings, and to the moral status of the machines themselves. The first section
discusses issues that may arise in the near future of AI. The second section outlines challenges
for ensuring that AI operates safely as it approaches humans in its intelligence.
The third section outlines how we might assess whether, and in what circumstances,
AIs themselves have moral status. In the fourth section, we consider how AIs might
differ from humans in certain basic respects relevant to our ethical assessment of them.
The final section addresses the issues of creating AIs more intelligent than human, and
ensuring that they use their advanced intelligence for good rather than ill. 

——引自论文由  
Nick Bostrom at Future of Humanity Institute  
Eliezer Yudkowsky at Machine Intelligence Research Institute   
所作论文 "The Ethics of Artificial Intelligence"   
源：https://intelligence.org/files/EthicsofAI.pdf

该论文全篇长达万余字，通篇分为四部分。  
第一部分讨论了AI不久的将来可能出现的问题。  
第二部分概述了确保人工智能在其智能接近人类时安全运行的挑战。  
第三部分概述了我们如何评估 AI 本身是否具有道德地位以及在何种情况下具有道德地位。  
在第四部分中，我们将考虑 AI 在某些与我们对其进行道德评估相关的基本方面可能与人类有何不同。  
最后一节讨论了创建 AI 比人类更聪明的问题，并确保他们使用先进的智能而不是生病。  
论文提出的中心论点是：由 AI 技术引起的一系列伦理问题既关系到确保这些机器不会伤害人类和其他道德相关的生物，也关系到机器本身的道德地位。  
这几个部分分别讨论了前述的9个热门话题中的前三个和第九个。

![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1543392195676&di=4125221b830ef4f0e8a3c0b69d2da137&imgtype=0&src=http%3A%2F%2F5b0988e595225.cdn.sohucs.com%2Fimages%2F20180917%2F05aedee99ede44d193a889b0464d92c7.jpg)

2. 观点二：
>"The difficulty is whether we recognize the inflection points as they come along and we take those opportunities to shape the technology."   — Wendel Wallach, Yale University  
>‘Breakthrough’ sessions to guide an ethical framework  
Many of the key breakthrough sessions at the Summit focused on the need for a guiding ethical framework and code of conduct, a theoretical “Hippocratic oath for AI” to direct the design, production, and use of AI and its applications for robotics.  
Delegates in the sessions debated key questions around AI applications for autonomous vehicles and drones, biomonitoring, healthcare robotics — and even for robots responsible for the maintenance of public order. And they recognized the challenge of anticipating key societal issues raised by emerging AI technologies that are changing at an exponential pace.  
“The difficulty is whether we recognize the inflection points as they come along and we take those opportunities to shape the technology,” said Wendel Wallach, scholar at Yale University’s Interdisciplinary Center for Bioethics, at the breakthrough session on ​Ethical Dev​elopment of AI.   
But ethics in the context of AI is more complex than identifying the where problems reside. Algorithm bias, for example, could potentially undermine the outputs of AI analysis.  
“We have to look at how we understand the implicit biases and inputs to understand what the biases are in the outputs,” said Wallach. “Can we do that technologically? If we can’t, what kind of restriction should we put on the deployment of the technology?”  
When machines make decisions, where do you draw the line
AI will soon be helping CEOs, doctors and surgeons make “better” decisions. “We’re delegating decisions to machines and, that is one of the biggest ethical questions: is it possible to draw a line?” asked Luka Omladič from UNESCO’s World Commission on the Ethics of Scientific Knowledge and Technology (COMEST.)  
Another point raised by Wallach is that new technologies are usually developed in the “rich north” and benefits are skewed in favor of those countries. “Those that have acquired the benefits are not necessarily those who are paying the price,” said Wallach. The emerging countries are usually the victims of economic disruption following technological advancements, he and others pointed out.  
As AI powered technologies can self-advance, there is a level of uncertainty in applying security measures and standards.  
In the breakthrough session on privacy and safety of AI, Virginia Dignum, from Delft University of Technology proposed the adoption of “ART principles” for AI, which include: Accountability – who is held to account; Responsibility – use and stewardship of data; and Transparency – being able to see beyond the “black box” and question the technical algorithms of AI.  
The development of AI is progressing at an exponential rate. The emerging technology could bring tremendous economic growth and social impact, but it could also cause social and economic disruption. Policymakers, innovators and researchers should recognize the potential risks and impact of AI to maximize its benefits for everyone, participants agreed.

节选自外网评述："How can we enhance the privacy, security and ethics of Artificial Intelligence?"

源：https://news.itu.int/privacy-security-and-ethics-of-ai/  
该文讨论的重点是上述议题中的第 6 个。

![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1543392293999&di=0f0069fe0461fcc5e8739eabf295c869&imgtype=0&src=http%3A%2F%2Finews.gtimg.com%2Fnewsapp_bt%2F0%2F5887805942%2F1000)

3. 观点三：  
>   凯菲特-巴特菲尔德说：“我需要对我的算法进行交叉检查，或者至少知道如何找出事故发生时的情况。”她是一名专攻人工智能问题的律师，同时也是艾奥斯汀的执行董事。她说，今年3月成立的非营利人工智能智库“道德顾问委员会”是由人工智能公司露西建立的伦理委员会。  
　　”我们需要一种方法来理解人工智能算法在做事情时“思考”的方式。你怎么能对一个病人的家人说，他们因为‘我们不知道是怎么发生的’AI干预而死亡？”因此，问责和透明度是很重要的。让你困惑的是为什么你的车会因为避让一只猫突然转向了一条狗，这并不是唯一需要提高透明度的人工智能问题。  
　　有偏见的人工智能算法会导致各种各样的问题。例如，面部识别系统可能会忽略有色人种，因为AI的训练数据库中没有关于有色人种的足够的面部特征，又比如：带有偏见的人工智能可能会自我强化，从而损害社会。如果社交媒体知道你喜欢看到一种政见的新闻，并且只向你展示这样的新闻，那么随着时间的推移，我们可能会失去批判性辩论的能力。  
　　'J.S穆勒提出了一个论点，如果想法没有受到挑战，那么它们就有可能成为教条。”Erden回忆道，很好地总结了她所说的“过滤泡沫”问题。（穆勒是一位19世纪的功利主义哲学家，他强烈支持基于经验证据的逻辑和推理，所以他很可能不会喜欢和Facebook上的人争论。）因此，如果人工智能创造出了数十亿人，他们不愿意，甚至没有能力分辨彼此的想法，这难道不是一个需要解决的道德问题吗？  
　　另一个问题是与机器人的情感关系的形成。菲尔德-巴特菲尔德感兴趣的是两种不同的范围——儿童和老年人。孩子们喜欢把自己不信任的东西放在身边，这使得他们与人工智能交流变得更容易接受。她担心人工智能机器人可能会让孩子们成为他们产品的理想客户。同样，另一方面，她也在思考人工智能机器人如何为老年人提供照顾和陪伴。   
　　“这是否会让人类没有与人类互动的权利，而只是被机器人照顾？”她说，“我认为这将是我们这个时代最重大的决定之一。”    
　　这凸显了人工智能的一个区别，即算法是如何做到的，以及我们想用它来实现什么。亚历克斯伦敦是卡内基梅隆大学道德与政策中心的哲学教授和主任，他说，推动问题的本质是机器想要做什么。这可能是最根本的问题之一。  
　　“如果机器出了问题，这是有问题的，那么道德编程（即它如何能在道德上提高这一目标）听起来是错误的，”他说，“这很棘手，因为很多都是出于人类自身的意图。”    
　　如果它能提高老年人的生活质量，作为频繁拜访和与家人通话的补充，机器人可能会很棒。但同样，以机器人作为借口忽视年长的亲戚，将会带来相反的后果。

引自：https://zhuanlan.zhihu.com/p/40245122
同样的，这段话也在讨论第六个议题，人工智能的安全性。

![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1543392373005&di=fe515475eba57f7c1d05b03e48183a6e&imgtype=0&src=http%3A%2F%2Fcms-bucket.nosdn.127.net%2Fa12078bf276342a9bdfeb2daeeb0c8d920180220164915.jpeg%3FimageView%26thumbnail%3D550x0)

总结：  
　　就像从厨房刀到核聚变的任何技术一样，这个工具本身不是好是坏，取决于使用它的人的意图。即使是这样，亚历克斯伦敦也指出，如果有人认为他们用这个工具做得很好，而其他人则不好，又是什么样的情况呢？  
　　对于这些道德问题，我们自己又是清醒的吗？随着人工智能的发展，这些问题已经开始显现出来。我们离智能机器人不远了，目前正在和那些愿意停止怀疑的人进行可行性的对话。 AI 时代的话题总是很多的，上述九个最热话题只是本文的讨论出发点，但只要我们用客观冷静的态度去审视，面对兴起的 AI 技术所带来的伦理问题，我们就能合理构建AI时代的伦理框架。
　　